{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "import yaml\n",
    "from torch.cuda import amp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.optim import Adam, SGD, lr_scheduler\n",
    "from tqdm import tqdm\n",
    "\n",
    "FILE = Path(\"train.py\").resolve()\n",
    "ROOT = FILE.parents[0]  # YOLOv5 root directory\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))  # add ROOT to PATH\n",
    "ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\n",
    "\n",
    "import val  # for end-of-epoch mAP\n",
    "from models.experimental import attempt_load\n",
    "from models.yolo import Model\n",
    "from utils.autoanchor import check_anchors\n",
    "from utils.datasets import create_dataloader\n",
    "from utils.general import labels_to_class_weights, increment_path, labels_to_image_weights, init_seeds, \\\n",
    "    strip_optimizer, get_latest_run, check_dataset, check_git_status, check_img_size, check_requirements, \\\n",
    "    check_file, check_yaml, check_suffix, print_args, print_mutation, set_logging, one_cycle, colorstr, methods\n",
    "from utils.downloads import attempt_download\n",
    "from utils.loss import ComputeLoss\n",
    "from utils.plots import plot_labels, plot_evolve\n",
    "from utils.torch_utils import EarlyStopping, ModelEMA, de_parallel, intersect_dicts, select_device, \\\n",
    "    torch_distributed_zero_first\n",
    "from utils.loggers.wandb.wandb_utils import check_wandb_resume\n",
    "from utils.metrics import fitness\n",
    "from utils.loggers import Loggers\n",
    "from utils.callbacks import Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGGER = logging.getLogger(__name__)\n",
    "LOCAL_RANK = int(os.getenv('LOCAL_RANK', -1))  # https://pytorch.org/docs/stable/elastic/run.html\n",
    "RANK = int(os.getenv('RANK', -1))\n",
    "WORLD_SIZE = int(os.getenv('WORLD_SIZE', 1))\n",
    "\n",
    "def copyfile(srcfile,dstpath):\n",
    "    if not os.path.isfile(srcfile):\n",
    "        print (\"%s not exist!\"%(srcfile))\n",
    "    else:\n",
    "        shutil.copy(srcfile, dstpath)\n",
    "        print (\"copy %s -> %s\"%(srcfile, dstpath ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(hyp,  # path/to/hyp.yaml or hyp dictionary\n",
    "          opt,\n",
    "          device,\n",
    "          callbacks\n",
    "          ):\n",
    "    save_dir, epochs, batch_size, weights, single_cls, evolve, data, cfg, resume, noval, nosave, workers, freeze, = \\\n",
    "        Path(opt.save_dir), opt.epochs, opt.batch_size, opt.weights, opt.single_cls, opt.evolve, opt.data, opt.cfg, \\\n",
    "        opt.resume, opt.noval, opt.nosave, opt.workers, opt.freeze\n",
    "\n",
    "    # Directories\n",
    "    w = save_dir / 'weights'  # weights dir\n",
    "    (w.parent if evolve else w).mkdir(parents=True, exist_ok=True)  # make dir\n",
    "    copyfile(opt.cfg, w)\n",
    "    last, best = w / 'last.pt', w / 'best.pt'\n",
    "\n",
    "    # Hyperparameters\n",
    "    if isinstance(hyp, str):\n",
    "        with open(hyp, errors='ignore') as f:\n",
    "            hyp = yaml.safe_load(f)  # load hyps dict\n",
    "    LOGGER.info(colorstr('hyperparameters: ') + ', '.join(f'{k}={v}' for k, v in hyp.items()))\n",
    "\n",
    "    # Save run settings\n",
    "    with open(save_dir / 'hyp.yaml', 'w') as f:\n",
    "        yaml.safe_dump(hyp, f, sort_keys=False)\n",
    "    with open(save_dir / 'opt.yaml', 'w') as f:\n",
    "        yaml.safe_dump(vars(opt), f, sort_keys=False)\n",
    "    data_dict = None\n",
    "\n",
    "    # Loggers\n",
    "    if RANK in [-1, 0]:\n",
    "        loggers = Loggers(save_dir, weights, opt, hyp, LOGGER)  # loggers instance\n",
    "        if loggers.wandb:\n",
    "            data_dict = loggers.wandb.data_dict\n",
    "            if resume:\n",
    "                weights, epochs, hyp = opt.weights, opt.epochs, opt.hyp\n",
    "\n",
    "        # Register actions\n",
    "        for k in methods(loggers):\n",
    "            callbacks.register_action(k, callback=getattr(loggers, k))\n",
    "\n",
    "    # Config\n",
    "    plots = not evolve  # create plots\n",
    "    cuda = device.type != 'cpu'\n",
    "    init_seeds(1 + RANK)\n",
    "    with torch_distributed_zero_first(LOCAL_RANK):\n",
    "        data_dict = data_dict or check_dataset(data)  # check if None\n",
    "    train_path, val_path = data_dict['train'], data_dict['val']\n",
    "    nc = 1 if single_cls else int(data_dict['nc'])  # number of classes\n",
    "    names = ['item'] if single_cls and len(data_dict['names']) != 1 else data_dict['names']  # class names\n",
    "    assert len(names) == nc, f'{len(names)} names found for nc={nc} dataset in {data}'  # check\n",
    "    is_coco = data.endswith('coco.yaml') and nc == 80  # COCO dataset\n",
    "\n",
    "    # Model\n",
    "    # check_suffix(weights, '.pt')  # check weights\n",
    "    pretrained = weights.endswith('.pt')\n",
    "    if pretrained:\n",
    "        with torch_distributed_zero_first(LOCAL_RANK):\n",
    "            weights = attempt_download(weights)  # download if not found locally\n",
    "        ckpt = torch.load(weights, map_location=device)  # load checkpoint\n",
    "        model = Model(cfg or ckpt['model'].yaml, ch=3, nc=nc, anchors=hyp.get('anchors')).to(device)  # create\n",
    "        exclude = ['anchor'] if (cfg or hyp.get('anchors')) and not resume else []  # exclude keys\n",
    "        csd = ckpt['model'].float().state_dict()  # checkpoint state_dict as FP32\n",
    "        csd = intersect_dicts(csd, model.state_dict(), exclude=exclude)  # intersect\n",
    "        model.load_state_dict(csd, strict=False)  # load\n",
    "        LOGGER.info(f'Transferred {len(csd)}/{len(model.state_dict())} items from {weights}')  # report\n",
    "    else:\n",
    "        model = Model(cfg, ch=3, nc=nc, anchors=hyp.get('anchors')).to(device)  # create\n",
    "\n",
    "    # Freeze\n",
    "    freeze = [f'model.{x}.' for x in range(freeze)]  # layers to freeze\n",
    "    for k, v in model.named_parameters():\n",
    "        v.requires_grad = True  # train all layers\n",
    "        if any(x in k for x in freeze):\n",
    "            print(f'freezing {k}')\n",
    "            v.requires_grad = False\n",
    "\n",
    "    # Optimizer\n",
    "    nbs = 64  # nominal batch size\n",
    "    accumulate = max(round(nbs / batch_size), 1)  # accumulate loss before optimizing\n",
    "    hyp['weight_decay'] *= batch_size * accumulate / nbs  # scale weight_decay\n",
    "    LOGGER.info(f\"Scaled weight_decay = {hyp['weight_decay']}\")\n",
    "\n",
    "    g0, g1, g2 = [], [], []  # optimizer parameter groups\n",
    "    for v in model.modules():\n",
    "        if hasattr(v, 'bias') and isinstance(v.bias, nn.Parameter):  # bias\n",
    "            g2.append(v.bias)\n",
    "        if isinstance(v, nn.BatchNorm2d):  # weight (no decay)\n",
    "            g0.append(v.weight)\n",
    "        elif hasattr(v, 'weight') and isinstance(v.weight, nn.Parameter):  # weight (with decay)\n",
    "            g1.append(v.weight)\n",
    "\n",
    "    if opt.adam:\n",
    "        optimizer = Adam(g0, lr=hyp['lr0'], betas=(hyp['momentum'], 0.999))  # adjust beta1 to momentum\n",
    "    else:\n",
    "        optimizer = SGD(g0, lr=hyp['lr0'], momentum=hyp['momentum'], nesterov=True)\n",
    "\n",
    "    optimizer.add_param_group({'params': g1, 'weight_decay': hyp['weight_decay']})  # add g1 with weight_decay\n",
    "    optimizer.add_param_group({'params': g2})  # add g2 (biases)\n",
    "    LOGGER.info(f\"{colorstr('optimizer:')} {type(optimizer).__name__} with parameter groups \"\n",
    "                f\"{len(g0)} weight, {len(g1)} weight (no decay), {len(g2)} bias\")\n",
    "    del g0, g1, g2\n",
    "\n",
    "    # Scheduler\n",
    "    if opt.linear_lr:\n",
    "        lf = lambda x: (1 - x / (epochs - 1)) * (1.0 - hyp['lrf']) + hyp['lrf']  # linear\n",
    "    else:\n",
    "        lf = one_cycle(1, hyp['lrf'], epochs)  # cosine 1->hyp['lrf']\n",
    "    scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lf)  # plot_lr_scheduler(optimizer, scheduler, epochs)\n",
    "\n",
    "    # EMA\n",
    "    ema = ModelEMA(model) if RANK in [-1, 0] else None\n",
    "\n",
    "    # Resume\n",
    "    start_epoch, best_fitness = 0, 0.0\n",
    "    if pretrained:\n",
    "        # Optimizer\n",
    "        if ckpt['optimizer'] is not None:\n",
    "            optimizer.load_state_dict(ckpt['optimizer'])\n",
    "            best_fitness = ckpt['best_fitness']\n",
    "\n",
    "        # EMA\n",
    "        if ema and ckpt.get('ema'):\n",
    "            ema.ema.load_state_dict(ckpt['ema'].float().state_dict())\n",
    "            ema.updates = ckpt['updates']\n",
    "\n",
    "        # Epochs\n",
    "        start_epoch = ckpt['epoch'] + 1\n",
    "        if resume:\n",
    "            assert start_epoch > 0, f'{weights} training to {epochs} epochs is finished, nothing to resume.'\n",
    "        if epochs < start_epoch:\n",
    "            LOGGER.info(f\"{weights} has been trained for {ckpt['epoch']} epochs. Fine-tuning for {epochs} more epochs.\")\n",
    "            epochs += ckpt['epoch']  # finetune additional epochs\n",
    "\n",
    "        del ckpt, csd\n",
    "\n",
    "    # Image sizes\n",
    "    gs = max(int(model.stride.max()), 32)  # grid size (max stride)\n",
    "    nl = model.model[-1].nl  # number of detection layers (used for scaling hyp['obj'])\n",
    "    imgsz = check_img_size(opt.imgsz, gs, floor=gs * 2)  # verify imgsz is gs-multiple\n",
    "\n",
    "    # DP mode\n",
    "    if cuda and RANK == -1 and torch.cuda.device_count() > 1:\n",
    "        logging.warning('DP not recommended, instead use torch.distributed.run for best DDP Multi-GPU results.\\n'\n",
    "                        'See Multi-GPU Tutorial at https://github.com/ultralytics/yolov5/issues/475 to get started.')\n",
    "        model = torch.nn.DataParallel(model)\n",
    "\n",
    "    # SyncBatchNorm\n",
    "    if opt.sync_bn and cuda and RANK != -1:\n",
    "        model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model).to(device)\n",
    "        LOGGER.info('Using SyncBatchNorm()')\n",
    "\n",
    "    # Trainloader\n",
    "    train_loader, dataset = create_dataloader(train_path, imgsz, batch_size // WORLD_SIZE, gs, single_cls,\n",
    "                                              hyp=hyp, augment=True, cache=opt.cache, rect=opt.rect, rank=LOCAL_RANK,\n",
    "                                              workers=workers, image_weights=opt.image_weights, quad=opt.quad,\n",
    "                                              prefix=colorstr('train: '))\n",
    "    mlc = int(np.concatenate(dataset.labels, 0)[:, 0].max())  # max label class\n",
    "    nb = len(train_loader)  # number of batches\n",
    "    assert mlc < nc, f'Label class {mlc} exceeds nc={nc} in {data}. Possible class labels are 0-{nc - 1}'\n",
    "\n",
    "    # Process 0\n",
    "    if RANK in [-1, 0]:\n",
    "        val_loader = create_dataloader(val_path, imgsz, batch_size // WORLD_SIZE * 2, gs, single_cls,\n",
    "                                       hyp=hyp, cache=None if noval else opt.cache, rect=True, rank=-1,\n",
    "                                       workers=workers, pad=0.5,\n",
    "                                       prefix=colorstr('val: '))[0]\n",
    "\n",
    "        if not resume:\n",
    "            labels = np.concatenate(dataset.labels, 0)\n",
    "            # c = torch.tensor(labels[:, 0])  # classes\n",
    "            # cf = torch.bincount(c.long(), minlength=nc) + 1.  # frequency\n",
    "            # model._initialize_biases(cf.to(device))\n",
    "            if plots:\n",
    "                plot_labels(labels, names, save_dir)\n",
    "\n",
    "            # Anchors\n",
    "            if not opt.noautoanchor:\n",
    "                check_anchors(dataset, model=model, thr=hyp['anchor_t'], imgsz=imgsz)\n",
    "            model.half().float()  # pre-reduce anchor precision\n",
    "\n",
    "        callbacks.run('on_pretrain_routine_end')\n",
    "\n",
    "    # DDP mode\n",
    "    if cuda and RANK != -1:\n",
    "        model = DDP(model, device_ids=[LOCAL_RANK], output_device=LOCAL_RANK)\n",
    "\n",
    "    # Model parameters\n",
    "    hyp['box'] *= 3. / nl  # scale to layers\n",
    "    hyp['cls'] *= nc / 80. * 3. / nl  # scale to classes and layers\n",
    "    hyp['obj'] *= (imgsz / 640) ** 2 * 3. / nl  # scale to image size and layers\n",
    "    hyp['label_smoothing'] = opt.label_smoothing\n",
    "    model.nc = nc  # attach number of classes to model\n",
    "    model.hyp = hyp  # attach hyperparameters to model\n",
    "    model.class_weights = labels_to_class_weights(dataset.labels, nc).to(device) * nc  # attach class weights\n",
    "    model.names = names\n",
    "\n",
    "    # Start training\n",
    "    t0 = time.time()\n",
    "    nw = max(round(hyp['warmup_epochs'] * nb), 1000)  # number of warmup iterations, max(3 epochs, 1k iterations)\n",
    "    # nw = min(nw, (epochs - start_epoch) / 2 * nb)  # limit warmup to < 1/2 of training\n",
    "    last_opt_step = -1\n",
    "    maps = np.zeros(nc)  # mAP per class\n",
    "    results = (0, 0, 0, 0, 0, 0, 0)  # P, R, mAP@.5, mAP@.5-.95, val_loss(box, obj, cls)\n",
    "    scheduler.last_epoch = start_epoch - 1  # do not move\n",
    "    scaler = amp.GradScaler(enabled=cuda)\n",
    "    stopper = EarlyStopping(patience=opt.patience)\n",
    "    compute_loss = ComputeLoss(model)  # init loss class\n",
    "    LOGGER.info(f'Image sizes {imgsz} train, {imgsz} val\\n'\n",
    "                f'Using {train_loader.num_workers} dataloader workers\\n'\n",
    "                f\"Logging results to {colorstr('bold', save_dir)}\\n\"\n",
    "                f'Starting training for {epochs} epochs...')\n",
    "    for epoch in range(start_epoch, epochs):  # epoch ------------------------------------------------------------------\n",
    "        model.train()\n",
    "\n",
    "        # Update image weights (optional, single-GPU only)\n",
    "        if opt.image_weights:\n",
    "            cw = model.class_weights.cpu().numpy() * (1 - maps) ** 2 / nc  # class weights\n",
    "            iw = labels_to_image_weights(dataset.labels, nc=nc, class_weights=cw)  # image weights\n",
    "            dataset.indices = random.choices(range(dataset.n), weights=iw, k=dataset.n)  # rand weighted idx\n",
    "\n",
    "        # Update mosaic border (optional)\n",
    "        # b = int(random.uniform(0.25 * imgsz, 0.75 * imgsz + gs) // gs * gs)\n",
    "        # dataset.mosaic_border = [b - imgsz, -b]  # height, width borders\n",
    "\n",
    "        mloss = torch.zeros(3, device=device)  # mean losses\n",
    "        if RANK != -1:\n",
    "            train_loader.sampler.set_epoch(epoch)\n",
    "        pbar = enumerate(train_loader)\n",
    "        LOGGER.info(('\\n' + '%10s' * 7) % ('Epoch', 'gpu_mem', 'box', 'obj', 'cls', 'labels', 'img_size'))\n",
    "        if RANK in [-1, 0]:\n",
    "            pbar = tqdm(pbar, total=nb)  # progress bar\n",
    "        optimizer.zero_grad()\n",
    "        for i, (imgs, targets, paths, _) in pbar:  # batch -------------------------------------------------------------\n",
    "            ni = i + nb * epoch  # number integrated batches (since train start)\n",
    "            imgs = imgs.to(device, non_blocking=True).float() / 255.0  # uint8 to float32, 0-255 to 0.0-1.0\n",
    "\n",
    "            # Warmup\n",
    "            if ni <= nw:\n",
    "                xi = [0, nw]  # x interp\n",
    "                # compute_loss.gr = np.interp(ni, xi, [0.0, 1.0])  # iou loss ratio (obj_loss = 1.0 or iou)\n",
    "                accumulate = max(1, np.interp(ni, xi, [1, nbs / batch_size]).round())\n",
    "                for j, x in enumerate(optimizer.param_groups):\n",
    "                    # bias lr falls from 0.1 to lr0, all other lrs rise from 0.0 to lr0\n",
    "                    x['lr'] = np.interp(ni, xi, [hyp['warmup_bias_lr'] if j == 2 else 0.0, x['initial_lr'] * lf(epoch)])\n",
    "                    if 'momentum' in x:\n",
    "                        x['momentum'] = np.interp(ni, xi, [hyp['warmup_momentum'], hyp['momentum']])\n",
    "\n",
    "            # Multi-scale\n",
    "            if opt.multi_scale:\n",
    "                sz = random.randrange(imgsz * 0.5, imgsz * 1.5 + gs) // gs * gs  # size\n",
    "                sf = sz / max(imgs.shape[2:])  # scale factor\n",
    "                if sf != 1:\n",
    "                    ns = [math.ceil(x * sf / gs) * gs for x in imgs.shape[2:]]  # new shape (stretched to gs-multiple)\n",
    "                    imgs = nn.functional.interpolate(imgs, size=ns, mode='bilinear', align_corners=False)\n",
    "\n",
    "            # Forward\n",
    "            with amp.autocast(enabled=cuda):\n",
    "                pred = model(imgs)  # forward\n",
    "                loss, loss_items = compute_loss(pred, targets.to(device))  # loss scaled by batch_size\n",
    "                if RANK != -1:\n",
    "                    loss *= WORLD_SIZE  # gradient averaged between devices in DDP mode\n",
    "                if opt.quad:\n",
    "                    loss *= 4.\n",
    "\n",
    "            # Backward\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            # Optimize\n",
    "            if ni - last_opt_step >= accumulate:\n",
    "                scaler.step(optimizer)  # optimizer.step\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "                if ema:\n",
    "                    ema.update(model)\n",
    "                last_opt_step = ni\n",
    "\n",
    "            # Log\n",
    "            if RANK in [-1, 0]:\n",
    "                mloss = (mloss * i + loss_items) / (i + 1)  # update mean losses\n",
    "                mem = f'{torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0:.3g}G'  # (GB)\n",
    "                pbar.set_description(('%10s' * 2 + '%10.4g' * 5) % (\n",
    "                    f'{epoch}/{epochs - 1}', mem, *mloss, targets.shape[0], imgs.shape[-1]))\n",
    "                callbacks.run('on_train_batch_end', ni, model, imgs, targets, paths, plots, opt.sync_bn)\n",
    "            # end batch ------------------------------------------------------------------------------------------------\n",
    "\n",
    "        # Scheduler\n",
    "        lr = [x['lr'] for x in optimizer.param_groups]  # for loggers\n",
    "        scheduler.step()\n",
    "\n",
    "        if RANK in [-1, 0]:\n",
    "            # mAP\n",
    "            callbacks.run('on_train_epoch_end', epoch=epoch)\n",
    "            ema.update_attr(model, include=['yaml', 'nc', 'hyp', 'names', 'stride', 'class_weights'])\n",
    "            final_epoch = (epoch + 1 == epochs) or stopper.possible_stop\n",
    "            if not noval or final_epoch:  # Calculate mAP\n",
    "                results, maps, _ = val.run(data_dict,\n",
    "                                           batch_size=batch_size // WORLD_SIZE * 2,\n",
    "                                           imgsz=imgsz,\n",
    "                                           model=ema.ema,\n",
    "                                           single_cls=single_cls,\n",
    "                                           dataloader=val_loader,\n",
    "                                           save_dir=save_dir,\n",
    "                                           plots=False,\n",
    "                                           callbacks=callbacks,\n",
    "                                           compute_loss=compute_loss)\n",
    "\n",
    "            # Update best mAP\n",
    "            fi = fitness(np.array(results).reshape(1, -1))  # weighted combination of [P, R, mAP@.5, mAP@.5-.95]\n",
    "            if fi > best_fitness:\n",
    "                best_fitness = fi\n",
    "            log_vals = list(mloss) + list(results) + lr\n",
    "            callbacks.run('on_fit_epoch_end', log_vals, epoch, best_fitness, fi)\n",
    "\n",
    "            # Save model\n",
    "            if (not nosave) or (final_epoch and not evolve):  # if save\n",
    "                ckpt = {'epoch': epoch,\n",
    "                        'best_fitness': best_fitness,\n",
    "                        'model': deepcopy(de_parallel(model)).half(),\n",
    "                        'ema': deepcopy(ema.ema).half(),\n",
    "                        'updates': ema.updates,\n",
    "                        'optimizer': optimizer.state_dict(),\n",
    "                        'wandb_id': loggers.wandb.wandb_run.id if loggers.wandb else None}\n",
    "\n",
    "                # Save last, best and delete\n",
    "                torch.save(ckpt, last)\n",
    "                if best_fitness == fi:\n",
    "                    torch.save(ckpt, best)\n",
    "                if (epoch > 0) and (opt.save_period > 0) and (epoch % opt.save_period == 0):\n",
    "                    torch.save(ckpt, w / f'epoch{epoch}.pt')\n",
    "                del ckpt\n",
    "                callbacks.run('on_model_save', last, epoch, final_epoch, best_fitness, fi)\n",
    "\n",
    "            # Stop Single-GPU\n",
    "            if RANK == -1 and stopper(epoch=epoch, fitness=fi):\n",
    "                break\n",
    "\n",
    "            # Stop DDP TODO: known issues shttps://github.com/ultralytics/yolov5/pull/4576\n",
    "            # stop = stopper(epoch=epoch, fitness=fi)\n",
    "            # if RANK == 0:\n",
    "            #    dist.broadcast_object_list([stop], 0)  # broadcast 'stop' to all ranks\n",
    "\n",
    "        # Stop DPP\n",
    "        # with torch_distributed_zero_first(RANK):\n",
    "        # if stop:\n",
    "        #    break  # must break all DDP ranks\n",
    "\n",
    "        # end epoch ----------------------------------------------------------------------------------------------------\n",
    "    # end training -----------------------------------------------------------------------------------------------------\n",
    "    if RANK in [-1, 0]:\n",
    "        LOGGER.info(f'\\n{epoch - start_epoch + 1} epochs completed in {(time.time() - t0) / 3600:.3f} hours.')\n",
    "        for f in last, best:\n",
    "            if f.exists():\n",
    "                strip_optimizer(f)  # strip optimizers\n",
    "                if f is best:\n",
    "                    LOGGER.info(f'\\nValidating {f}...')\n",
    "                    results, _, _ = val.run(data_dict,\n",
    "                                            batch_size=batch_size // WORLD_SIZE * 2,\n",
    "                                            imgsz=imgsz,\n",
    "                                            model=attempt_load(f, device).half(),\n",
    "                                            iou_thres=0.65 if is_coco else 0.60,  # best pycocotools results at 0.65\n",
    "                                            single_cls=single_cls,\n",
    "                                            dataloader=val_loader,\n",
    "                                            save_dir=save_dir,\n",
    "                                            save_json=is_coco,\n",
    "                                            verbose=True,\n",
    "                                            plots=True,\n",
    "                                            callbacks=callbacks,\n",
    "                                            compute_loss=compute_loss)  # val best model with plots\n",
    "\n",
    "        callbacks.run('on_train_end', last, best, plots, epoch)\n",
    "        LOGGER.info(f\"Results saved to {colorstr('bold', save_dir)}\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Opt:\n",
    "    def __init__(self):\n",
    "        self.weights = ROOT / ''\n",
    "        self.cfg = ROOT /'models/yolov5s.yaml'\n",
    "        self.data = ROOT / 'data/myvoc.yaml'\n",
    "        self.hyp = ROOT / 'data/hyps/hyp.scratch-high.yaml'\n",
    "        self.project = ROOT / 'runs/train'\n",
    "        self.epochs = 300\n",
    "        self.batch_size = 30\n",
    "        self.imgsz = 640\n",
    "        self.img = 640\n",
    "        self.img_size = 640\n",
    "        self.rect = False\n",
    "        self.device = ''\n",
    "        self.adam=False\n",
    "        self.artifact_alias='latest'\n",
    "        self.bbox_interval=-1\n",
    "        self.bucket=''\n",
    "        self.cache=None\n",
    "        self.entity=None\n",
    "        self.evolve=None\n",
    "        self.exist_ok=False\n",
    "        self.freeze=0\n",
    "        self.image_weights=False\n",
    "        self.label_smoothing=0.0\n",
    "        self.linear_lr=False\n",
    "        self.local_rank=-1\n",
    "        self.multi_scale=False\n",
    "        self.name = \"src_data\"\n",
    "        self.noautoanchor=False\n",
    "        self.nosave=False\n",
    "        self.noval=False\n",
    "        self.patience=100\n",
    "        self.quad=False\n",
    "        self.resume=False\n",
    "        self.save_period=-1\n",
    "        self.single_cls=False\n",
    "        self.upload_dataset=False\n",
    "        self.workers=8\n",
    "        self.sync_bn=False\n",
    "\n",
    "\n",
    "def parse_opt(known=False):\n",
    "    opt = Opt()\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(opt, callbacks=Callbacks()):\n",
    "    # Checks\n",
    "    set_logging(RANK)\n",
    "    if RANK in [-1, 0]:\n",
    "        print_args(FILE.stem, opt)\n",
    "        check_git_status()\n",
    "        check_requirements(exclude=['thop'])\n",
    "\n",
    "    # Resume\n",
    "    if opt.resume and not check_wandb_resume(opt) and not opt.evolve:  # resume an interrupted run\n",
    "        ckpt = opt.resume if isinstance(opt.resume, str) else get_latest_run()  # specified or most recent path\n",
    "        assert os.path.isfile(ckpt), 'ERROR: --resume checkpoint does not exist'\n",
    "        with open(Path(ckpt).parent.parent / 'opt.yaml', errors='ignore') as f:\n",
    "            opt = argparse.Namespace(**yaml.safe_load(f))  # replace\n",
    "        opt.cfg, opt.weights, opt.resume = '', ckpt, True  # reinstate\n",
    "        LOGGER.info(f'Resuming training from {ckpt}')\n",
    "    else:\n",
    "        opt.data, opt.cfg, opt.hyp, opt.weights, opt.project = \\\n",
    "            check_file(opt.data), check_yaml(opt.cfg), check_yaml(opt.hyp), str(opt.weights), str(opt.project)  # checks\n",
    "        assert len(opt.cfg) or len(opt.weights), 'either --cfg or --weights must be specified'\n",
    "        if opt.evolve:\n",
    "            opt.project = str(ROOT / 'runs/evolve')\n",
    "            opt.exist_ok, opt.resume = opt.resume, False  # pass resume to exist_ok and disable resume\n",
    "        opt.save_dir = str(increment_path(Path(opt.project) / opt.name, exist_ok=opt.exist_ok))\n",
    "\n",
    "    # DDP mode\n",
    "    device = select_device(opt.device, batch_size=opt.batch_size)\n",
    "    if LOCAL_RANK != -1:\n",
    "        assert torch.cuda.device_count() > LOCAL_RANK, 'insufficient CUDA devices for DDP command'\n",
    "        assert opt.batch_size % WORLD_SIZE == 0, '--batch-size must be multiple of CUDA device count'\n",
    "        assert not opt.image_weights, '--image-weights argument is not compatible with DDP training'\n",
    "        assert not opt.evolve, '--evolve argument is not compatible with DDP training'\n",
    "        torch.cuda.set_device(LOCAL_RANK)\n",
    "        device = torch.device('cuda', LOCAL_RANK)\n",
    "        dist.init_process_group(backend=\"nccl\" if dist.is_nccl_available() else \"gloo\")\n",
    "\n",
    "    # Train\n",
    "    if not opt.evolve:\n",
    "        train(opt.hyp, opt, device, callbacks)\n",
    "        if WORLD_SIZE > 1 and RANK == 0:\n",
    "            LOGGER.info('Destroying process group... ')\n",
    "            dist.destroy_process_group()\n",
    "\n",
    "    # Evolve hyperparameters (optional)\n",
    "    else:\n",
    "        # Hyperparameter evolution metadata (mutation scale 0-1, lower_limit, upper_limit)\n",
    "        meta = {'lr0': (1, 1e-5, 1e-1),  # initial learning rate (SGD=1E-2, Adam=1E-3)\n",
    "                'lrf': (1, 0.01, 1.0),  # final OneCycleLR learning rate (lr0 * lrf)\n",
    "                'momentum': (0.3, 0.6, 0.98),  # SGD momentum/Adam beta1\n",
    "                'weight_decay': (1, 0.0, 0.001),  # optimizer weight decay\n",
    "                'warmup_epochs': (1, 0.0, 5.0),  # warmup epochs (fractions ok)\n",
    "                'warmup_momentum': (1, 0.0, 0.95),  # warmup initial momentum\n",
    "                'warmup_bias_lr': (1, 0.0, 0.2),  # warmup initial bias lr\n",
    "                'box': (1, 0.02, 0.2),  # box loss gain\n",
    "                'cls': (1, 0.2, 4.0),  # cls loss gain\n",
    "                'cls_pw': (1, 0.5, 2.0),  # cls BCELoss positive_weight\n",
    "                'obj': (1, 0.2, 4.0),  # obj loss gain (scale with pixels)\n",
    "                'obj_pw': (1, 0.5, 2.0),  # obj BCELoss positive_weight\n",
    "                'iou_t': (0, 0.1, 0.7),  # IoU training threshold\n",
    "                'anchor_t': (1, 2.0, 8.0),  # anchor-multiple threshold\n",
    "                'anchors': (2, 2.0, 10.0),  # anchors per output grid (0 to ignore)\n",
    "                'fl_gamma': (0, 0.0, 2.0),  # focal loss gamma (efficientDet default gamma=1.5)\n",
    "                'hsv_h': (1, 0.0, 0.1),  # image HSV-Hue augmentation (fraction)\n",
    "                'hsv_s': (1, 0.0, 0.9),  # image HSV-Saturation augmentation (fraction)\n",
    "                'hsv_v': (1, 0.0, 0.9),  # image HSV-Value augmentation (fraction)\n",
    "                'degrees': (1, 0.0, 45.0),  # image rotation (+/- deg)\n",
    "                'translate': (1, 0.0, 0.9),  # image translation (+/- fraction)\n",
    "                'scale': (1, 0.0, 0.9),  # image scale (+/- gain)\n",
    "                'shear': (1, 0.0, 10.0),  # image shear (+/- deg)\n",
    "                'perspective': (0, 0.0, 0.001),  # image perspective (+/- fraction), range 0-0.001\n",
    "                'flipud': (1, 0.0, 1.0),  # image flip up-down (probability)\n",
    "                'fliplr': (0, 0.0, 1.0),  # image flip left-right (probability)\n",
    "                'mosaic': (1, 0.0, 1.0),  # image mixup (probability)\n",
    "                'mixup': (1, 0.0, 1.0),  # image mixup (probability)\n",
    "                'copy_paste': (1, 0.0, 1.0)}  # segment copy-paste (probability)\n",
    "\n",
    "        with open(opt.hyp, errors='ignore') as f:\n",
    "            hyp = yaml.safe_load(f)  # load hyps dict\n",
    "            if 'anchors' not in hyp:  # anchors commented in hyp.yaml\n",
    "                hyp['anchors'] = 3\n",
    "        opt.noval, opt.nosave, save_dir = True, True, Path(opt.save_dir)  # only val/save final epoch\n",
    "        # ei = [isinstance(x, (int, float)) for x in hyp.values()]  # evolvable indices\n",
    "        evolve_yaml, evolve_csv = save_dir / 'hyp_evolve.yaml', save_dir / 'evolve.csv'\n",
    "        if opt.bucket:\n",
    "            os.system(f'gsutil cp gs://{opt.bucket}/evolve.csv {save_dir}')  # download evolve.csv if exists\n",
    "\n",
    "        for _ in range(opt.evolve):  # generations to evolve\n",
    "            if evolve_csv.exists():  # if evolve.csv exists: select best hyps and mutate\n",
    "                # Select parent(s)\n",
    "                parent = 'single'  # parent selection method: 'single' or 'weighted'\n",
    "                x = np.loadtxt(evolve_csv, ndmin=2, delimiter=',', skiprows=1)\n",
    "                n = min(5, len(x))  # number of previous results to consider\n",
    "                x = x[np.argsort(-fitness(x))][:n]  # top n mutations\n",
    "                w = fitness(x) - fitness(x).min() + 1E-6  # weights (sum > 0)\n",
    "                if parent == 'single' or len(x) == 1:\n",
    "                    # x = x[random.randint(0, n - 1)]  # random selection\n",
    "                    x = x[random.choices(range(n), weights=w)[0]]  # weighted selection\n",
    "                elif parent == 'weighted':\n",
    "                    x = (x * w.reshape(n, 1)).sum(0) / w.sum()  # weighted combination\n",
    "\n",
    "                # Mutate\n",
    "                mp, s = 0.8, 0.2  # mutation probability, sigma\n",
    "                npr = np.random\n",
    "                npr.seed(int(time.time()))\n",
    "                g = np.array([meta[k][0] for k in hyp.keys()])  # gains 0-1\n",
    "                ng = len(meta)\n",
    "                v = np.ones(ng)\n",
    "                while all(v == 1):  # mutate until a change occurs (prevent duplicates)\n",
    "                    v = (g * (npr.random(ng) < mp) * npr.randn(ng) * npr.random() * s + 1).clip(0.3, 3.0)\n",
    "                for i, k in enumerate(hyp.keys()):  # plt.hist(v.ravel(), 300)\n",
    "                    hyp[k] = float(x[i + 7] * v[i])  # mutate\n",
    "\n",
    "            # Constrain to limits\n",
    "            for k, v in meta.items():\n",
    "                hyp[k] = max(hyp[k], v[1])  # lower limit\n",
    "                hyp[k] = min(hyp[k], v[2])  # upper limit\n",
    "                hyp[k] = round(hyp[k], 5)  # significant digits\n",
    "\n",
    "            # Train mutation\n",
    "            results = train(hyp.copy(), opt, device, callbacks)\n",
    "\n",
    "            # Write mutation results\n",
    "            print_mutation(results, hyp.copy(), save_dir, opt.bucket)\n",
    "\n",
    "        # Plot results\n",
    "        plot_evolve(evolve_csv)\n",
    "        print(f'Hyperparameter evolution finished\\n'\n",
    "              f\"Results saved to {colorstr('bold', save_dir)}\\n\"\n",
    "              f'Use best hyperparameters example: $ python train.py --hyp {evolve_yaml}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=., cfg=models\\yolov5s.yaml, data=data\\myvoc.yaml, hyp=data\\hyps\\hyp.scratch-high.yaml, project=runs\\train, epochs=300, batch_size=30, imgsz=640, img=640, img_size=640, rect=False, device=, adam=False, artifact_alias=latest, bbox_interval=-1, bucket=, cache=None, entity=None, evolve=None, exist_ok=False, freeze=0, image_weights=False, label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name=src_data, noautoanchor=False, nosave=False, noval=False, patience=100, quad=False, resume=False, save_period=-1, single_cls=False, upload_dataset=False, workers=8, sync_bn=False\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  1c026f3 torch 1.9.0+cu111 CUDA:0 (NVIDIA GeForce GTX 1660 Ti, 6143.6875MB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.1, copy_paste=0.1\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "up to date with https://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@github.com/YangyuBaobao/yolov5 \n",
      "copy models\\yolov5s.yaml -> runs\\train\\src_data2\\weights\n",
      "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5  runs (RECOMMENDED)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3169  models.common.GhostBottleneck           [3, 64, 3, 2]                 \n",
      "  1                -1  1      8720  models.common.GhostBottleneck           [64, 64, 3, 2]                \n",
      "  2                -1  1     12088  models.common.TCSP_Ghost2               [64, 64, 1]                   \n",
      "  3                -1  1     18784  models.common.GhostBottleneck           [64, 128, 3, 2]               \n",
      "  4                -1  2     55312  models.common.TCSP_Ghost2               [128, 128, 2]                 \n",
      "  5                -1  1     66240  models.common.GhostBottleneck           [128, 256, 3, 2]              \n",
      "  6                -1  3    246264  models.common.TCSP_Ghost2               [256, 256, 3]                 \n",
      "  7                -1  1    247168  models.common.GhostBottleneck           [256, 512, 3, 2]              \n",
      "  8                -1  1    667624  models.common.TCSP_Ghost2               [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1     69248  models.common.GSConv                    [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    219328  models.common.VoVGSCSP                  [512, 256, 1, False]          \n",
      " 14                -1  1     18240  models.common.GSConv                    [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     56416  models.common.VoVGSCSP                  [256, 128, 1, False]          \n",
      " 18                -1  1     75584  models.common.GSConv                    [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    186560  models.common.VoVGSCSP                  [256, 256, 1, False]          \n",
      " 21                -1  1    298624  models.common.GSConv                    [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1    733568  models.common.VoVGSCSP                  [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model Summary: 688 layers, 3656015 parameters, 3656015 gradients\n",
      "\n",
      "Scaled weight_decay = 0.00046875\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 142 weight, 145 weight (no decay), 145 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'VOCdevkit\\labels\\train.cache' images and labels... 126 found, 0 missing, 0 empty, 0 corrupted: 100%|██████████| 126/126 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'VOCdevkit\\labels\\val.cache' images and labels... 44 found, 0 missing, 0 empty, 0 corrupted: 100%|██████████| 44/44 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\train\\src_data2\u001b[0m\n",
      "Starting training for 300 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 3.58, Best Possible Recall (BPR) = 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 11088, 12272, 5152) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32me:\\Python\\virtualenv\\inductionNet\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    989\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 990\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    991\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\developapp\\python 38\\lib\\queue.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    177\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_5592/1536297272.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse_opt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_5592/1782042897.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m(opt, callbacks)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;31m# Train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevolve\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mWORLD_SIZE\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mRANK\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mLOGGER\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Destroying process group... '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_5592/149523475.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(hyp, opt, device, callbacks)\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[0mpbar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpbar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnb\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# progress bar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpaths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# batch -------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m             \u001b[0mni\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnb\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mepoch\u001b[0m  \u001b[1;31m# number integrated batches (since train start)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m             \u001b[0mimgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255.0\u001b[0m  \u001b[1;31m# uint8 to float32, 0-255 to 0.0-1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Python\\virtualenv\\inductionNet\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1184\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1185\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1186\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m                 \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Orders\\ProjectSequence\\CV-yolo\\yolov5-6.0-xingren\\utils\\datasets.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Python\\virtualenv\\inductionNet\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Python\\virtualenv\\inductionNet\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1186\u001b[1;33m             \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Python\\virtualenv\\inductionNet\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1140\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1142\u001b[1;33m                 \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1143\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1144\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Python\\virtualenv\\inductionNet\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1001\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfailed_workers\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1002\u001b[0m                 \u001b[0mpids_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m', '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfailed_workers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1003\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DataLoader worker (pid(s) {}) exited unexpectedly'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpids_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1004\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 11088, 12272, 5152) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "\n",
    "opt = parse_opt()\n",
    "main(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inductionNet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
